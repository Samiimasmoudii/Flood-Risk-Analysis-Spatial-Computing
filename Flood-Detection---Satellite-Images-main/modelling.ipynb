{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess \n",
    "from subprocess import PIPE\n",
    "import rasterio\n",
    "import json\n",
    "import glob \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The local folder path where the labels are stored\n",
    "path_labels = '/workspaces/Flood-Risk-Analysis-Spatial-Computing/Flood-Detection---Satellite-Images-main/data/SEN12-FLOOD/Sentinel_2/sen12floods_s2_labels'\n",
    "\n",
    "# The local folder where the training images are stored\n",
    "path_training_images = '/workspaces/Flood-Risk-Analysis-Spatial-Computing/Flood-Detection---Satellite-Images-main/data/SEN12-FLOOD/Sentinel_2/Images/sen12floods_s2_source>3'\n",
    "\n",
    "# The local folder where the testing images are stored\n",
    "path_testing_images = '/workspaces/Flood-Risk-Analysis-Spatial-Computing/Flood-Detection---Satellite-Images-main/data/SEN12-FLOOD/Sentinel_2/Images/sen12floods_s2_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def image_label(product_id, s1_json_path, s2_json_path):\n",
    "    \"\"\"\n",
    "    Determines if the given image depicts a flooded area based on labels in S1list and S2list JSON files.\n",
    "\n",
    "    Args:\n",
    "        product_id (str): The name of the image file.\n",
    "        s1_json_path (str): Path to the S1list JSON file.\n",
    "        s2_json_path (str): Path to the S2list JSON file.\n",
    "\n",
    "    Returns:\n",
    "        int: 1 if the image depicts a flooded area, 0 otherwise.\n",
    "    \"\"\"\n",
    "    def search_label_in_json(json_path, product_id):\n",
    "        \"\"\"\n",
    "        Searches for the product_id in the given JSON file and returns the FLOODING label if found.\n",
    "\n",
    "        Args:\n",
    "            json_path (str): Path to the JSON file.\n",
    "            product_id (str): The image file name to search for.\n",
    "\n",
    "        Returns:\n",
    "            int or None: 1 for flooding, 0 for no flooding, None if not found.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(json_path):\n",
    "            raise FileNotFoundError(f\"JSON file not found: {json_path}\")\n",
    "        \n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "        \n",
    "        # Iterate through entries in the JSON file to match the product_id\n",
    "        for entry in data.values():\n",
    "            if isinstance(entry, dict) and entry.get(\"filename\") == product_id:\n",
    "                flooding = entry.get(\"FLOODING\")\n",
    "                return 1 if flooding else 0\n",
    "        \n",
    "        return None  # Return None if the product_id is not found\n",
    "    \n",
    "    # Search in S1list JSON\n",
    "    label = search_label_in_json(s1_json_path, product_id)\n",
    "    if label is not None:\n",
    "        return label\n",
    "    \n",
    "    # Search in S2list JSON\n",
    "    label = search_label_in_json(s2_json_path, product_id)\n",
    "    if label is not None:\n",
    "        return label\n",
    "    \n",
    "    # If not found in either file, raise an exception or handle as needed\n",
    "    raise ValueError(f\"Product ID '{product_id}' not found in either S1list or S2list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions accepts as argument the name of the image and it searches for the coresponding label. \n",
    "# If the image depicts a flooded area then it returns the number one (1) otherwise it returns the number zero (0)\n",
    "\n",
    "def image_label(product_id):\n",
    "    \n",
    "    rootdir = \"/workspaces/Flood-Risk-Analysis-Spatial-Computing/Flood-Detection---Satellite-Images-main/data/SEN12-FLOOD/Sentinel_2/Images/sen12floods_s2_source\"\n",
    "    pd = product_id.split(\"_\")\n",
    "    pd = pd[3] + \"_\" + pd[4] + \"_\" + pd[5] + \"_\" + pd[6]\n",
    "    \n",
    "    json_data=open(rootdir + pd +\"/stac.json\", \"rb\")\n",
    "    jdata = json.load(json_data)\n",
    "    flood = jdata[\"properties\"][\"FLOODING\"]\n",
    "    \n",
    "\n",
    "    if (flood == \"False\"):\n",
    "        image_label = 0\n",
    "    else:\n",
    "        image_label = 1\n",
    "    \n",
    "    return image_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function it accepts as argument the path of the folder where the image is stored.\n",
    "# Inside this folder there is a json file containing the product id as a property\n",
    "# It return the product id\n",
    "\n",
    "def product_name(path):\n",
    "    \n",
    "    json_data=open(path+\"/stac.json\", \"rb\")\n",
    "    jdata = json.load(json_data)\n",
    "    \n",
    "    return  jdata['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is responsible for constructing the dataset in a way compatible with keras.\n",
    "# It iterates through folders and searches for images along with their coresponding label.\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    data = [] \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in imagelist:\n",
    "        try:\n",
    "            product_id = product_name(folder)\n",
    "            print(f\"Processing {product_id} image product\")\n",
    "            label = image_label(product_id)\n",
    "        \n",
    "            # Open the img\n",
    "            image = cv2.imread(folder + \"/stack.tif\")\n",
    "            # Append the image and its corresponding label to the output\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "        \n",
    "        \n",
    "    data.append([images, labels])     \n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is currently = 3\n"
     ]
    }
   ],
   "source": [
    "# Create a list with all the folders containing spectral bands\n",
    "\n",
    "\n",
    "imagelist = []\n",
    "rootdir = path_training_images\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        imagelist.append(d)\n",
    "        \n",
    "        \n",
    "print(f\"The number of training samples is currently = {len(imagelist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of testing samples is = 3\n"
     ]
    }
   ],
   "source": [
    "# Create a list with all the folders containing spectral bands\n",
    "\n",
    "\n",
    "imagelist = []\n",
    "rootdir = path_testing_images # define the path for the folder\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        imagelist.append(d)\n",
    "        \n",
    "        \n",
    "print(f\"The number of testing samples is = {len(imagelist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m (unique, counts) \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(test_labels, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(unique, counts)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of images in the test dataset containing flooded areas is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounts[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhile the number of images clean from floods is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Calculate the number of images in the test set \n",
    "# containing Flooded areas and the number of images that does not contain flooded areas\n",
    "\n",
    "(unique, counts) = np.unique(test_labels, return_counts=True)\n",
    "\n",
    "# print(unique, counts)\n",
    "print(f\"The number of images in the test dataset containing flooded areas is {counts[1]}\\n\")\n",
    "print(f\"While the number of images clean from floods is {counts[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m (unique, counts) \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(train_labels, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(unique, counts)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of images in the train dataset containing flooded areas is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounts[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhile the number of images clean from floods is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Calculate the number of images in the training set \n",
    "# containing Flooded areas and the number of images that does not contain flooded areas\n",
    "\n",
    "(unique, counts) = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "# print(unique, counts)\n",
    "print(f\"The number of images in the train dataset containing flooded areas is {counts[1]}\\n\")\n",
    "print(f\"While the number of images clean from floods is {counts[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the Deep Learing modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "\n",
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (512, 512, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 510, 510, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 255, 255, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 253, 253, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 126, 126, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 508032)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               65028224  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,038,626\n",
      "Trainable params: 65,038,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model on the available training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)  # Should match the input shape defined in the first layer of the model\n",
    "print(train_labels.shape)  # Should match the number of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flood_mapping/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/flood_mapping/lib/python3.8/site-packages/keras/engine/training.py:1662\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1660\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `train_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty logs). Please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1669\u001b[0m     )\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_get_metrics_result(logs)\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=1, epochs=20)\n",
    "#history = model.fit(train_images, train_labels, batch_size=1, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"my_model\")\n",
    "# model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['acc'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_acc'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction with VGG ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features directly from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features calculated earlier\n",
    "np.save(\"train_features.npy\", train_features)\n",
    "np.save(\"test_features\", test_features)\n",
    "\n",
    "# Load the trained weights\n",
    "# loaded_array = np.load(\"train_features.npy\")\n",
    "# loaded_array = np.load(\"test_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, x, y, z = train_features.shape\n",
    "n_test, x, y, z = test_features.shape\n",
    "numFeatures = x * y * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on top of VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a simple one-layer Neural Network on the features extracted from VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_features, train_labels, batch_size=28, epochs=30, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model2.evaluate(test_features, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flood_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
